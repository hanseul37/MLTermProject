{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2j-8myO3NaQ",
    "outputId": "0ea3cb4c-17e2-4a3d-a2b1-b22d272074ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.1.3)\r\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-surprise) (1.3.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-surprise) (1.22.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-surprise) (1.11.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jevNSFGzaa22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QbewLOR_bAz8"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"preprocessed_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pUDEvMAvbGd5"
   },
   "outputs": [],
   "source": [
    "# Surprise 라이브러리용 Reader 객체 생성\n",
    "reader = Reader(rating_scale=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LDF21phqCsTd"
   },
   "outputs": [],
   "source": [
    "# Surprise 데이터셋으로 변환\n",
    "surprise_data = Dataset.load_from_df(data[['직무, 지역', '회사명', '총점']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "t9fOWXh2JLfZ"
   },
   "outputs": [],
   "source": [
    "# 전체 데이터를 학습 데이터셋으로 사용\n",
    "trainset = surprise_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "E_diGVvTGnR2"
   },
   "outputs": [],
   "source": [
    "# SVD 모델 생성\n",
    "model = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5MScMFrGswq",
    "outputId": "67a86829-d5a3-4024-eafd-9206f29fa912"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f0739578760>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7LCBusPjJZ9p"
   },
   "outputs": [],
   "source": [
    "# 유저의 평점\n",
    "ex_ratings = pd.DataFrame({'회사명': ['CJ씨푸드', 'LG전자'], '평점': ['10', '80']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ApGPZH8zLe9w"
   },
   "outputs": [],
   "source": [
    "# 예시 유저가 평가한 기업 목록\n",
    "rated_companies = ex_ratings['회사명'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "s2ago3xXMzkr"
   },
   "outputs": [],
   "source": [
    "# 예시 유저가 평가하지 않은 기업 목록\n",
    "unrated_companies = [company for company in data['회사명'].unique() if company not in rated_companies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fD4BgbyXNDHi"
   },
   "outputs": [],
   "source": [
    "# 예시 유저의 평가하지 않은 기업에 대한 평점 예측\n",
    "predictions = [(company, model.predict('직무, 지역', company).est) for company in unrated_companies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "z4zst2GQNVB4"
   },
   "outputs": [],
   "source": [
    "# 예측 결과를 데이터프레임으로 변환\n",
    "recommendations_df = pd.DataFrame(predictions, columns=['회사명', '평점'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fkAhrRTeNaYI"
   },
   "outputs": [],
   "source": [
    "# 예측 평점이 높은 순으로 정렬하여 상위 10개 기업 추천\n",
    "top_n_recommendations = recommendations_df.sort_values(by='평점', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GH-KznMMXPS",
    "outputId": "45e5515e-f004-462f-b185-0d1277d1b02e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             회사명         평점\n",
      "320        스마트전자  59.416763\n",
      "1799      한국전력기술  59.071446\n",
      "783   연세고운미소치과의원  58.951284\n",
      "61         바디텍메드  58.807774\n",
      "654       에스피씨삼립  58.784468\n",
      "1661      한국남동발전  58.761900\n",
      "1678      한국동서발전  58.541611\n",
      "124       부산교통공사  58.482237\n",
      "834          오존텍  58.390737\n",
      "1694    한국무역보험공사  58.387609\n"
     ]
    }
   ],
   "source": [
    "print(top_n_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "from sagemaker import Session\n",
    "import sagemaker.amazon.common as smac\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Set up SageMaker session and S3 bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = 'sagemaker-ml1-job'\n",
    "prefix = 'model_based_CF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "arn:aws:iam::629515838455:role/service-role/AmazonSageMaker-ExecutionRole-20231207T141059\n"
     ]
    }
   ],
   "source": [
    "# Get the IAM role\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 2002 2295\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of customers, products, and feature dimensions\n",
    "nb_customer = data['직무_지역_idx'].max() + 1\n",
    "nb_product = data['회사명_idx'].max() + 1\n",
    "feature_dim = nb_customer + nb_products\n",
    "print(nb_customer, nb_products, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>직무_지역_idx</th>\n",
       "      <th>회사명_idx</th>\n",
       "      <th>총점</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   직무_지역_idx  회사명_idx    총점\n",
       "0         50        0  60.0\n",
       "1        117        0  70.0\n",
       "2        133        0  40.0\n",
       "3        136        1  40.0\n",
       "4        190        1  40.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relevant columns from the data\n",
    "product_df = data[['직무_지역_idx', '회사명_idx', '총점']]\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the dataframe to a sparse matrix\n",
    "def convert_sparse_matrix(df, nb_rows, nb_customer, nb_products):\n",
    "    # Convert dataframe to array\n",
    "    df_val = df.values\n",
    "\n",
    "    # Determine feature size\n",
    "    nb_cols = nb_customer + nb_products\n",
    "    print(\"# of rows = {}\".format(str(nb_rows)))\n",
    "    print(\"# of cols = {}\".format(str(nb_cols)))\n",
    "\n",
    "    # Extract customers and ratings\n",
    "    df_X = df_val[:, 0:2]\n",
    "    # Features are one-hot encoded in a sparse matrix\n",
    "    X = lil_matrix((nb_rows, nb_cols)).astype('float32')\n",
    "    df_X[:, 1] = nb_customer + df_X[:, 1]\n",
    "    coords = df_X[:, 0:2]\n",
    "    X[np.arange(nb_rows), coords[:, 0]] = 1\n",
    "    X[np.arange(nb_rows), coords[:, 1]] = 1\n",
    "\n",
    "    # Create label with ratings\n",
    "    Y = df_val[:, 2].astype('float32')\n",
    "\n",
    "    # Validate size and shape\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    assert X.shape == (nb_rows, nb_cols)\n",
    "    assert Y.shape == (nb_rows, )\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows = 6571\n",
      "# of cols = 2295\n",
      "(6571, 2295)\n",
      "(6571,)\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataframe to sparse matrix format\n",
    "X, Y = convert_sparse_matrix(product_df, product_df.shape[0], nb_customer, nb_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the sparse matrix to a buffer\n",
    "buf = io.BytesIO() \n",
    "smac.write_spmatrix_to_sparse_tensor(buf, X, y)\n",
    "buf.seek(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'preprocessed_review.protobuf')).upload_fileobj(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define S3 paths for training data and model output\n",
    "s3_train_data = 's3://{}/{}/{}'.format(bucket, prefix, 'preprocessed_review.protobuf')\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "WARNING:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712309505854.dkr.ecr.ap-southeast-2.amazonaws.com/factorization-machines:1\n"
     ]
    }
   ],
   "source": [
    "# Get the factorization machines container\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'factorization-machines', 'latest')\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Create an Estimator for training the factorization machines model\n",
    "fm_model = sagemaker.estimator.Estimator(container,\n",
    "                                         role,         \n",
    "                                         train_instance_count = 1,\n",
    "                                         train_instance_type='ml.c4.xlarge',\n",
    "                                         output_path=output_location,\n",
    "                                         sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for the factorization machines model\n",
    "fm_model.set_hyperparameters(feature_dim=feature_dim,\n",
    "                      predictor_type='regressor',\n",
    "                      mini_batch_size=200,\n",
    "                      num_factors=512,\n",
    "                      bias_lr=0.02,\n",
    "                      epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: factorization-machines-2023-12-09-05-55-55-487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 05:55:55 Starting - Starting the training job...\n",
      "2023-12-09 05:56:09 Starting - Preparing the instances for training......\n",
      "2023-12-09 05:57:11 Downloading - Downloading input data...\n",
      "2023-12-09 05:57:41 Training - Downloading the training image............\n",
      "2023-12-09 05:59:47 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'bias_lr': '0.02', 'epochs': '10', 'feature_dim': '2295', 'mini_batch_size': '200', 'num_factors': '512', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] Final configuration: {'epochs': '10', 'mini_batch_size': '200', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.02', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '2295', 'num_factors': '512', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 WARNING 139917187471168] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] Using default worker.\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:58.272] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1, \"num_examples\": 1, \"num_bytes\": 12800}\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.2704642, \"EndTime\": 1702101598.3072712, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 35.08281707763672, \"count\": 1, \"min\": 35.08281707763672, \"max\": 35.08281707763672}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.3074076, \"EndTime\": 1702101598.3074572, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 200.0, \"count\": 1, \"min\": 200, \"max\": 200}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 200.0, \"count\": 1, \"min\": 200, \"max\": 200}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[05:59:58] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.363.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[05:59:58] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.363.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[05:59:58] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.363.0/AL2_x86_64/generic-flavor/src/src/operator/././../common/utils.h:450: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=58.738799464238284\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=3450.2465625\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=53.746748046875\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:58.529] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 163, \"num_examples\": 33, \"num_bytes\": 420544}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=59.25093129941912\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=0, train mse <loss>=3510.6728598484847\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=54.639206764914775\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.307348, \"EndTime\": 1702101598.5299594, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"update.time\": {\"sum\": 222.2146987915039, \"count\": 1, \"min\": 222.2146987915039, \"max\": 222.2146987915039}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.3077123, \"EndTime\": 1702101598.5302696, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6771.0, \"count\": 1, \"min\": 6771, \"max\": 6771}, \"Total Batches Seen\": {\"sum\": 34.0, \"count\": 1, \"min\": 34, \"max\": 34}, \"Max Records Seen Between Resets\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Max Batches Seen Between Resets\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Number of Batches Since Last Reset\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #throughput_metric: host=algo-1, train throughput=29507.625713312962 records/second\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=58.11518734375723\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=3377.375\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=53.06396484375\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:58.684] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 148, \"num_examples\": 33, \"num_bytes\": 420544}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=58.6218692224699\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=1, train mse <loss>=3436.5235511363635\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=53.96218823982007\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.5300534, \"EndTime\": 1702101598.6847012, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 154.10757064819336, \"count\": 1, \"min\": 154.10757064819336, \"max\": 154.10757064819336}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.5305634, \"EndTime\": 1702101598.6849785, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13342.0, \"count\": 1, \"min\": 13342, \"max\": 13342}, \"Total Batches Seen\": {\"sum\": 67.0, \"count\": 1, \"min\": 67, \"max\": 67}, \"Max Records Seen Between Resets\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Max Batches Seen Between Resets\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Number of Batches Since Last Reset\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #throughput_metric: host=algo-1, train throughput=42512.963443885536 records/second\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=57.495774301247565\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=3305.7640625\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=52.3843505859375\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:58.818] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 129, \"num_examples\": 33, \"num_bytes\": 420544}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=57.99736001698176\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=2, train mse <loss>=3363.693768939394\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=53.28878048058712\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.6847823, \"EndTime\": 1702101598.8194566, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 134.1409683227539, \"count\": 1, \"min\": 134.1409683227539, \"max\": 134.1409683227539}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.6852856, \"EndTime\": 1702101598.8196602, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19913.0, \"count\": 1, \"min\": 19913, \"max\": 19913}, \"Total Batches Seen\": {\"sum\": 100.0, \"count\": 1, \"min\": 100, \"max\": 100}, \"Max Records Seen Between Resets\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Max Batches Seen Between Resets\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Number of Batches Since Last Reset\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #throughput_metric: host=algo-1, train throughput=48852.06460486947 records/second\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=56.88105736974305\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=3235.4546875\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=51.70845703125\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:58.979] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 156, \"num_examples\": 33, \"num_bytes\": 420544}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=57.37763668266478\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=3, train mse <loss>=3292.1931912878786\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=52.619215198863635\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.8195279, \"EndTime\": 1702101598.980533, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 160.56203842163086, \"count\": 1, \"min\": 160.56203842163086, \"max\": 160.56203842163086}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.8199406, \"EndTime\": 1702101598.9809194, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26484.0, \"count\": 1, \"min\": 26484, \"max\": 26484}, \"Total Batches Seen\": {\"sum\": 133.0, \"count\": 1, \"min\": 133, \"max\": 133}, \"Max Records Seen Between Resets\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Max Batches Seen Between Resets\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Number of Batches Since Last Reset\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:58 INFO 139917187471168] #throughput_metric: host=algo-1, train throughput=40779.90356325887 records/second\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=56.27115157876192\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=3166.4425\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=51.0363720703125\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:59.156] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 166, \"num_examples\": 33, \"num_bytes\": 420544}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=56.76267404529783\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=4, train mse <loss>=3222.0011647727274\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=51.953448449337124\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.9806457, \"EndTime\": 1702101599.1571233, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 175.8122444152832, \"count\": 1, \"min\": 175.8122444152832, \"max\": 175.8122444152832}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101598.981278, \"EndTime\": 1702101599.157372, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33055.0, \"count\": 1, \"min\": 33055, \"max\": 33055}, \"Total Batches Seen\": {\"sum\": 166.0, \"count\": 1, \"min\": 166, \"max\": 166}, \"Max Records Seen Between Resets\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Max Batches Seen Between Resets\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Number of Batches Since Last Reset\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #throughput_metric: host=algo-1, train throughput=37285.40063637741 records/second\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=55.6660494601512\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=3098.7090625\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=50.3680419921875\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:59.313] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 152, \"num_examples\": 33, \"num_bytes\": 420544}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=56.15240531897152\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=5, train mse <loss>=3153.0926231060607\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=51.291387162642046\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.1572027, \"EndTime\": 1702101599.314339, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 156.6600799560547, \"count\": 1, \"min\": 156.6600799560547, \"max\": 156.6600799560547}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.157648, \"EndTime\": 1702101599.3145692, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 39626.0, \"count\": 1, \"min\": 39626, \"max\": 39626}, \"Total Batches Seen\": {\"sum\": 199.0, \"count\": 1, \"min\": 199, \"max\": 199}, \"Max Records Seen Between Resets\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Max Batches Seen Between Resets\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Number of Batches Since Last Reset\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #throughput_metric: host=algo-1, train throughput=41840.01588540164 records/second\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=55.06570223378614\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=3032.2315625\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=49.70337890625\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:59.467] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 148, \"num_examples\": 33, \"num_bytes\": 420544}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=55.54674807395037\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=6, train mse <loss>=3085.441221590909\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=50.632924952651514\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.3144135, \"EndTime\": 1702101599.46841, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 153.55944633483887, \"count\": 1, \"min\": 153.55944633483887, \"max\": 153.55944633483887}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.3148205, \"EndTime\": 1702101599.468652, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 46197.0, \"count\": 1, \"min\": 46197, \"max\": 46197}, \"Total Batches Seen\": {\"sum\": 232.0, \"count\": 1, \"min\": 232, \"max\": 232}, \"Max Records Seen Between Resets\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Max Batches Seen Between Resets\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Number of Batches Since Last Reset\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #throughput_metric: host=algo-1, train throughput=42678.53185005327 records/second\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=54.47005197812831\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=2966.9865625\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=49.042294921875\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:59.649] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 176, \"num_examples\": 33, \"num_bytes\": 420544}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=54.94561485556478\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=7, train mse <loss>=3019.0205918560605\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=49.97794537168561\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.4684908, \"EndTime\": 1702101599.6502512, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 181.30803108215332, \"count\": 1, \"min\": 181.30803108215332, \"max\": 181.30803108215332}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.4689112, \"EndTime\": 1702101599.6506095, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 52768.0, \"count\": 1, \"min\": 52768, \"max\": 52768}, \"Total Batches Seen\": {\"sum\": 265.0, \"count\": 1, \"min\": 265, \"max\": 265}, \"Max Records Seen Between Resets\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Max Batches Seen Between Resets\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Number of Batches Since Last Reset\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #throughput_metric: host=algo-1, train throughput=36126.2753410993 records/second\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=53.879036971720275\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=2902.950625\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=48.3846923828125\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:59.821] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 164, \"num_examples\": 33, \"num_bytes\": 420544}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=54.34891593974766\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=8, train mse <loss>=2953.8046638257574\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=49.326331084280305\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.6503375, \"EndTime\": 1702101599.8219295, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 170.93372344970703, \"count\": 1, \"min\": 170.93372344970703, \"max\": 170.93372344970703}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.650966, \"EndTime\": 1702101599.822305, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 59339.0, \"count\": 1, \"min\": 59339, \"max\": 59339}, \"Total Batches Seen\": {\"sum\": 298.0, \"count\": 1, \"min\": 298, \"max\": 298}, \"Max Records Seen Between Resets\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Max Batches Seen Between Resets\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Number of Batches Since Last Reset\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #throughput_metric: host=algo-1, train throughput=38314.9293139929 records/second\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=53.29258860291926\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=2840.1\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=47.7304638671875\u001b[0m\n",
      "\u001b[34m[2023-12-09 05:59:59.992] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 165, \"num_examples\": 33, \"num_bytes\": 420544}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=53.75656663552272\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=9, train mse <loss>=2889.768456439394\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=48.677965346827655\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, train rmse <loss>=53.75656663552272\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, train mse <loss>=2889.768456439394\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #quality_metric: host=algo-1, train absolute_loss <loss>=48.677965346827655\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.8220549, \"EndTime\": 1702101599.9937212, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 170.88985443115234, \"count\": 1, \"min\": 170.88985443115234, \"max\": 170.88985443115234}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.8228016, \"EndTime\": 1702101599.9939387, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 65910.0, \"count\": 1, \"min\": 65910, \"max\": 65910}, \"Total Batches Seen\": {\"sum\": 331.0, \"count\": 1, \"min\": 331, \"max\": 331}, \"Max Records Seen Between Resets\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Max Batches Seen Between Resets\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 6571.0, \"count\": 1, \"min\": 6571, \"max\": 6571}, \"Number of Batches Since Last Reset\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] #throughput_metric: host=algo-1, train throughput=38368.48246041447 records/second\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 WARNING 139917187471168] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[12/09/2023 05:59:59 INFO 139917187471168] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.9938128, \"EndTime\": 1702101599.9985, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 4.298925399780273, \"count\": 1, \"min\": 4.298925399780273, \"max\": 4.298925399780273}}}\u001b[0m\n",
      "\u001b[34m[12/09/2023 06:00:00 INFO 139917187471168] Saved checkpoint to \"/tmp/tmpfsummj6y/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[12/09/2023 06:00:00 INFO 139917187471168] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1702101599.998579, \"EndTime\": 1702101600.0279996, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 17.726421356201172, \"count\": 1, \"min\": 17.726421356201172, \"max\": 17.726421356201172}, \"totaltime\": {\"sum\": 1778.1956195831299, \"count\": 1, \"min\": 1778.1956195831299, \"max\": 1778.1956195831299}}}\u001b[0m\n",
      "\n",
      "2023-12-09 06:00:19 Uploading - Uploading generated training model\n",
      "2023-12-09 06:00:19 Completed - Training job completed\n",
      "Training seconds: 188\n",
      "Billable seconds: 188\n"
     ]
    }
   ],
   "source": [
    "# Train the factorization machines model\n",
    "fm_model.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: factorization-machines-2023-12-09-06-01-30-551\n",
      "INFO:sagemaker:Creating endpoint-config with name factorization-machines-2023-12-09-06-01-30-551\n",
      "INFO:sagemaker:Creating endpoint with name factorization-machines-2023-12-09-06-01-30-551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "# Deploying the model to perform inference \n",
    "\n",
    "predictor = fm_model.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 엔드포인트 삭제\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
